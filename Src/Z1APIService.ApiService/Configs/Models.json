[
  {
    "chatModels": [
      {
        "contextWindowTokens": 128000,
        "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。",
        "displayName": "OpenAI o1-mini",
        "enabled": true,
        "id": "o1-mini",
        "type": "chat",
        "maxOutput": 65536,
        "pricing": {
          "input": 3,
          "output": 12
        },
        "releasedAt": "2024-09-12"
      },
      {
        "contextWindowTokens": 200000,
        "description": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。",
        "displayName": "OpenAI o1",
        "enabled": true,
        "id": "o1-2024-12-17",
        "type": "chat",
        "maxOutput": 100000,
        "pricing": {
          "input": 15,
          "output": 60
        },
        "releasedAt": "2024-12-17",
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。",
        "displayName": "OpenAI o1-preview",
        "enabled": true,
        "type": "chat",
        "id": "o1-preview",
        "maxOutput": 32768,
        "pricing": {
          "input": 15,
          "output": 60
        },
        "releasedAt": "2024-09-12"
      },
      {
        "contextWindowTokens": 128000,
        "description": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。",
        "displayName": "GPT-4o mini",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o-mini",
        "maxOutput": 16385,
        "pricing": {
          "input": 0.15,
          "output": 0.6
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "displayName": "GPT-4o 1120",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o-2024-11-20",
        "pricing": {
          "input": 2.5,
          "output": 10
        },
        "releasedAt": "2024-11-20",
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "displayName": "GPT-4o",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "gpt-4o",
        "pricing": {
          "input": 2.5,
          "output": 10
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "displayName": "GPT-4o 0806",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o-2024-08-06",
        "pricing": {
          "input": 2.5,
          "output": 10
        },
        "releasedAt": "2024-08-06",
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "displayName": "GPT-4o 0513",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o-2024-05-13",
        "pricing": {
          "input": 5,
          "output": 15
        },
        "releasedAt": "2024-05-13",
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",
        "displayName": "ChatGPT-4o",
        "enabled": true,
        "type": "chat",
        "id": "chatgpt-4o-latest",
        "pricing": {
          "input": 5,
          "output": 15
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
        "displayName": "GPT-4 Turbo",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4-turbo",
        "pricing": {
          "input": 10,
          "output": 30
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
        "displayName": "GPT-4 Turbo Vision 0409",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4-turbo-2024-04-09",
        "pricing": {
          "input": 10,
          "output": 30
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
        "displayName": "GPT-4 Turbo Preview",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4-turbo-preview",
        "pricing": {
          "input": 10,
          "output": 30
        }
      },
      {
        "contextWindowTokens": 128000,
        "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
        "displayName": "GPT-4 Turbo Preview 0125",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4-0125-preview",
        "pricing": {
          "input": 10,
          "output": 30
        }
      },
      {
        "contextWindowTokens": 128000,
        "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",
        "displayName": "GPT-4 Turbo Preview 1106",
        "type": "chat",
        "functionCall": true,
        "id": "gpt-4-1106-preview",
        "pricing": {
          "input": 10,
          "output": 30
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
        "displayName": "GPT-4",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4",
        "pricing": {
          "input": 30,
          "output": 60
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
        "displayName": "GPT-4 0613",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4-0613",
        "pricing": {
          "input": 30,
          "output": 60
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
        "displayName": "GPT-4 32K",
        "type": "chat",
        "functionCall": true,
        "id": "gpt-4-32k",
        "pricing": {
          "input": 60,
          "output": 120
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。",
        "displayName": "GPT-4 32K 0613",
        "type": "chat",
        "functionCall": true,
        "id": "gpt-4-32k-0613",
        "pricing": {
          "input": 60,
          "output": 120
        }
      },
      {
        "contextWindowTokens": 16385,
        "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
        "displayName": "GPT-3.5 Turbo",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-3.5-turbo",
        "pricing": {
          "input": 0.5,
          "output": 1.5
        }
      },
      {
        "contextWindowTokens": 16385,
        "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
        "displayName": "GPT-3.5 Turbo 0125",
        "functionCall": true,
        "type": "chat",
        "id": "gpt-3.5-turbo-0125",
        "pricing": {
          "input": 0.5,
          "output": 1.5
        }
      },
      {
        "contextWindowTokens": 16385,
        "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
        "displayName": "GPT-3.5 Turbo 1106",
        "type": "chat",
        "functionCall": true,
        "id": "gpt-3.5-turbo-1106",
        "pricing": {
          "input": 1,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125",
        "displayName": "GPT-3.5 Turbo Instruct",
        "id": "gpt-3.5-turbo-instruct",
        "type": "chat",
        "pricing": {
          "input": 1.5,
          "output": 2
        }
      }
    ],
    "provider": "OpenAI"
  },
  {
    "provider": "DeepSeek",
    "chatModels": [
      {
        "contextWindowTokens": 65536,
        "description": "最新模型 DeepSeek-V3 多项评测成绩超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，性能对齐领军闭源模型 GPT-4o 与 Claude-3.5-Sonnet。",
        "displayName": "DeepSeek V3",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "deepseek-chat",
        "pricing": {
          "cachedInput": 0.1,
          "input": 1,
          "output": 2
        },
        "releasedAt": "2024-12-26"
      },
      {
        "contextWindowTokens": 65536,
        "description": "DeepSeek 推出的推理模型。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。",
        "displayName": "DeepSeek R1",
        "enabled": true,
        "type": "chat",
        "id": "deepseek-reasoner",
        "pricing": {
          "cachedInput": 1,
          "input": 4,
          "output": 16
        },
        "releasedAt": "2025-01-20"
      }
    ]
  },
  {
    "provider": "Google",
    "chatModels": [
      {
        "contextWindowTokens": 2105344,
        "description": "Gemini 2.0 Pro Experimental 是 Google 最新的实验性多模态AI模型，与历史版本相比有一定的质量提升，特别是对于世界知识、代码和长上下文。",
        "displayName": "Gemini 2.0 Pro Experimental 02-05",
        "enabled": true,
        "functionCall": true,
        "id": "gemini-2.0-pro-exp-02-05",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05",
        "vision": true
      },
      {
        "contextWindowTokens": 1056768,
        "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。",
        "displayName": "Gemini 2.0 Flash",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "gemini-2.0-flash",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.025,
          "input": 0.1,
          "output": 0.4
        },
        "releasedAt": "2025-02-05",
        "vision": true
      },
      {
        "contextWindowTokens": 1056768,
        "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。",
        "displayName": "Gemini 2.0 Flash 001",
        "functionCall": true,
        "id": "gemini-2.0-flash-001",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.025,
          "input": 0.1,
          "output": 0.4
        },
        "releasedAt": "2025-02-05",
        "vision": true
      },
      {
        "contextWindowTokens": 1056768,
        "description": "一个 Gemini 2.0 Flash 模型，针对成本效益和低延迟等目标进行了优化。",
        "displayName": "Gemini 2.0 Flash-Lite Preview 02-05",
        "id": "gemini-2.0-flash-lite-preview-02-05",
        "maxOutput": 8192,
        "type": "chat",
        "pricing": {
          "cachedInput": 0.01875,
          "input": 0.075,
          "output": 0.3
        },
        "releasedAt": "2025-02-05",
        "vision": true
      },
      {
        "contextWindowTokens": 1056768,
        "description": "Gemini Exp 1206 是 Google 的实验性多模态AI模型，与历史版本相比有一定的质量提升。",
        "displayName": "Gemini Experimental 1206",
        "functionCall": true,
        "id": "gemini-exp-1206",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2024-12-06",
        "vision": true
      },
      {
        "contextWindowTokens": 1114112,
        "description": "Gemini 2.0 Flash Thinking Exp 是 Google 的实验性多模态推理AI模型，能对复杂问题进行推理，拥有新的思维能力。",
        "displayName": "Gemini 2.0 Flash Thinking Experimental 01-21",
        "enabled": true,
        "id": "gemini-2.0-flash-thinking-exp-01-21",
        "maxOutput": 65536,
        "type": "chat",
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-01-21",
        "vision": true
      },
      {
        "contextWindowTokens": 40959,
        "description": "Gemini 2.0 Flash Thinking Exp 是 Google 的实验性多模态推理AI模型，能对复杂问题进行推理，拥有新的思维能力。",
        "displayName": "Gemini 2.0 Flash Thinking Experimental 12-19",
        "id": "gemini-2.0-flash-thinking-exp-1219",
        "maxOutput": 8192,
        "type": "chat",
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2024-12-19",
        "vision": true
      },
      {
        "contextWindowTokens": 1056768,
        "description": "Gemini 2.0 Flash Exp 是 Google 的实验性多模态AI模型，拥有下一代特性，卓越的速度，原生工具调用以及多模态生成。",
        "displayName": "Gemini 2.0 Flash Experimental",
        "functionCall": true,
        "id": "gemini-2.0-flash-exp",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2024-12-11",
        "vision": true
      },
      {
        "contextWindowTokens": 40959,
        "description": "LearnLM 是一个实验性的、特定于任务的语言模型，经过训练以符合学习科学原则，可在教学和学习场景中遵循系统指令，充当专家导师等。",
        "displayName": "LearnLM 1.5 Pro Experimental",
        "functionCall": true,
        "id": "learnlm-1.5-pro-experimental",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0,
          "input": 0,
          "output": 0
        },
        "releasedAt": "2024-11-19",
        "vision": true
      },
      {
        "contextWindowTokens": 1008192,
        "description": "Gemini 1.5 Flash 002 是一款高效的多模态模型，支持广泛应用的扩展。",
        "displayName": "Gemini 1.5 Flash 002",
        "functionCall": true,
        "id": "gemini-1.5-flash-002",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.01875,
          "input": 0.075,
          "output": 0.3
        },
        "releasedAt": "2024-09-25",
        "vision": true
      },
      {
        "contextWindowTokens": 1008192,
        "description": "Gemini 1.5 Flash 001 是一款高效的多模态模型，支持广泛应用的扩展。",
        "displayName": "Gemini 1.5 Flash 001",
        "functionCall": true,
        "id": "gemini-1.5-flash-001",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.01875,
          "input": 0.075,
          "output": 0.3
        },
        "vision": true
      },
      {
        "contextWindowTokens": 2008192,
        "description": "Gemini 1.5 Pro 002 是最新的生产就绪模型，提供更高质量的输出，特别在数学、长上下文和视觉任务方面有显著提升。",
        "displayName": "Gemini 1.5 Pro 002",
        "functionCall": true,
        "id": "gemini-1.5-pro-002",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.315,
          "input": 1.25,
          "output": 2.5
        },
        "releasedAt": "2024-09-24",
        "vision": true
      },
      {
        "contextWindowTokens": 2008192,
        "description": "Gemini 1.5 Pro 001 是可扩展的多模态AI解决方案，支持广泛的复杂任务。",
        "displayName": "Gemini 1.5 Pro 001",
        "type": "chat",
        "functionCall": true,
        "id": "gemini-1.5-pro-001",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.875,
          "input": 3.5,
          "output": 10.5
        },
        "releasedAt": "2024-02-15",
        "vision": true
      },
      {
        "contextWindowTokens": 1008192,
        "description": "Gemini 1.5 Flash 8B 是一款高效的多模态模型，支持广泛应用的扩展。",
        "displayName": "Gemini 1.5 Flash 8B",
        "functionCall": true,
        "id": "gemini-1.5-flash-8b",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.02,
          "input": 0.075,
          "output": 0.3
        },
        "releasedAt": "2024-10-03",
        "vision": true
      },
      {
        "contextWindowTokens": 1008192,
        "description": "Gemini 1.5 Flash 8B 0924 是最新的实验性模型，在文本和多模态用例中都有显著的性能提升。",
        "displayName": "Gemini 1.5 Flash 8B 0924",
        "functionCall": true,
        "id": "gemini-1.5-flash-8b-exp-0924",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.01875,
          "input": 0.075,
          "output": 0.3
        },
        "releasedAt": "2024-09-24",
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "Gemini 1.0 Pro 001 (Tuning) 提供稳定并可调优的性能，是复杂任务解决方案的理想选择。",
        "displayName": "Gemini 1.0 Pro 001 (Tuning)",
        "functionCall": true,
        "id": "gemini-1.0-pro-001",
        "type": "chat",
        "maxOutput": 2048,
        "pricing": {
          "input": 0.5,
          "output": 1.5
        },
        "releasedAt": "2023-12-06"
      },
      {
        "contextWindowTokens": 32768,
        "description": "Gemini 1.0 Pro 002 (Tuning) 提供出色的多模态支持，专注于复杂任务的有效解决。",
        "displayName": "Gemini 1.0 Pro 002 (Tuning)",
        "functionCall": true,
        "id": "gemini-1.0-pro-002",
        "type": "chat",
        "maxOutput": 2048,
        "pricing": {
          "input": 0.5,
          "output": 1.5
        },
        "releasedAt": "2023-12-06"
      }
    ]
  },
  {
    "provider": "Anthropic",
    "chatModels": [
      {
        "contextWindowTokens": 200000,
        "description": " Claude 3.7 Sonnet 是 Anthropic 迄今为止最尖端的 AI，引入了“扩展思维”能力。这一特性使模型能够通过系统化、逐步推理的方式解决复杂问题。它还首次在 AI 行业中允许用户在快速响应（标准思维）和深度推理（扩展思维）之间切换，从而根据具体应用场景的需求提供灵活性。",
        "displayName": "Claude 3.7 sonnet 推理",
        "enabled": true,
        "functionCall": true,
        "id": "claude-3-7-sonnet-20250219-thinking",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.1,
          "input": 3.7,
          "output": 5,
          "writeCacheInput": 1.25
        },
        "releasedAt": "2025-02-19"
      },
      {
        "contextWindowTokens": 200000,
        "description": " Claude 3.7 Sonnet 是 Anthropic 迄今为止最尖端的 AI，引入了“扩展思维”能力。这一特性使模型能够通过系统化、逐步推理的方式解决复杂问题。它还首次在 AI 行业中允许用户在快速响应（标准思维）和深度推理（扩展思维）之间切换，从而根据具体应用场景的需求提供灵活性。",
        "displayName": "Claude 3.7 sonnet",
        "enabled": true,
        "functionCall": true,
        "id": "claude-3-7-sonnet-20250219",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.1,
          "input": 3.7,
          "output": 5,
          "writeCacheInput": 1.25
        },
        "releasedAt": "2025-02-19"
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",
        "displayName": "Claude 3.5 Haiku",
        "enabled": true,
        "functionCall": true,
        "id": "claude-3-5-haiku-20241022",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.1,
          "input": 1,
          "output": 5,
          "writeCacheInput": 1.25
        },
        "releasedAt": "2024-11-05"
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
        "displayName": "Claude 3.5 Sonnet",
        "enabled": true,
        "functionCall": true,
        "id": "claude-3-5-sonnet-20241022",
        "maxOutput": 8192,
        "type": "chat",
        "pricing": {
          "cachedInput": 0.3,
          "input": 3,
          "output": 15,
          "writeCacheInput": 3.75
        },
        "releasedAt": "2024-10-22",
        "vision": true
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",
        "displayName": "Claude 3.5 Sonnet 0620",
        "functionCall": true,
        "id": "claude-3-5-sonnet-20240620",
        "type": "chat",
        "maxOutput": 8192,
        "pricing": {
          "cachedInput": 0.3,
          "input": 3,
          "output": 15,
          "writeCacheInput": 3.75
        },
        "releasedAt": "2024-06-20",
        "vision": true
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。",
        "displayName": "Claude 3 Haiku",
        "functionCall": true,
        "id": "claude-3-haiku-20240307",
        "type": "chat",
        "maxOutput": 4096,
        "pricing": {
          "input": 0.25,
          "output": 1.25
        },
        "releasedAt": "2024-03-07",
        "vision": true
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3 Sonnet 在智能和速度方面为企业工作负载提供了理想的平衡。它以更低的价格提供最大效用，可靠且适合大规模部署。",
        "displayName": "Claude 3 Sonnet",
        "functionCall": true,
        "id": "claude-3-sonnet-20240229",
        "type": "chat",
        "maxOutput": 4096,
        "pricing": {
          "input": 3,
          "output": 15
        },
        "releasedAt": "2024-02-29",
        "vision": true
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。",
        "displayName": "Claude 3 Opus",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "claude-3-opus-20240229",
        "maxOutput": 4096,
        "pricing": {
          "input": 15,
          "output": 75
        },
        "releasedAt": "2024-02-29",
        "vision": true
      },
      {
        "contextWindowTokens": 200000,
        "description": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。",
        "displayName": "Claude 2.1",
        "type": "chat",
        "id": "claude-2.1",
        "maxOutput": 4096,
        "pricing": {
          "input": 8,
          "output": 24
        },
        "releasedAt": "2023-11-21"
      },
      {
        "contextWindowTokens": 100000,
        "description": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。",
        "displayName": "Claude 2.0",
        "type": "chat",
        "id": "claude-2.0",
        "maxOutput": 4096,
        "pricing": {
          "input": 8,
          "output": 24
        },
        "releasedAt": "2023-07-11"
      }
    ]
  },
  {
    "provider": "SiliconCloud",
    "chatModels": [
      {
        "contextWindowTokens": 65536,
        "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。",
        "displayName": "DeepSeek R1",
        "type": "chat",
        "enabled": true,
        "id": "deepseek-ai/DeepSeek-R1",
        "pricing": {
          "currency": "CNY",
          "input": 4,
          "output": 16
        }
      },
      {
        "contextWindowTokens": 65536,
        "description": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
        "displayName": "DeepSeek V3",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "deepseek-ai/DeepSeek-V3",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 65536,
        "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。",
        "displayName": "DeepSeek R1 (Pro)",
        "id": "Pro/deepseek-ai/DeepSeek-R1",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 4,
          "output": 16
        }
      },
      {
        "contextWindowTokens": 65536,
        "description": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
        "displayName": "DeepSeek V3 (Pro)",
        "functionCall": true,
        "type": "chat",
        "id": "Pro/deepseek-ai/DeepSeek-V3",
        "pricing": {
          "currency": "CNY",
          "input": 2,
          "output": 8
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Llama-70B 是基于 Llama-3.3-70B-Instruct 经过蒸馏训练得到的模型。该模型是 DeepSeek-R1 系列的一部分，通过使用 DeepSeek-R1 生成的样本进行微调，在数学、编程和推理等多个领域展现出优秀的性能。模型在 AIME 2024、MATH-500、GPQA Diamond 等多个基准测试中都取得了优异的成绩，显示出强大的推理能力。",
        "displayName": "DeepSeek R1 Distill Llama 70B",
        "enabled": true,
        "type": "chat",
        "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。在 AIME 2024、MATH-500、GPQA Diamond 等多个基准测试中都取得了优异成绩，其中在 MATH-500 上达到了 94.3% 的准确率，展现出强大的数学推理能力。",
        "displayName": "DeepSeek R1 Distill Qwen 32B",
        "enabled": true,
        "type": "chat",
        "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 93.9% 的准确率，在 AIME 2024 上达到了 69.7% 的通过率，在 CodeForces 上获得了 1481 的评分，显示出在数学和编程领域的强大实力。",
        "displayName": "DeepSeek R1 Distill Qwen 14B",
        "type": "chat",
        "enabled": true,
        "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "pricing": {
          "currency": "CNY",
          "input": 0.7,
          "output": 0.7
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Llama-8B 是基于 Llama-3.1-8B 开发的蒸馏模型。该模型使用 DeepSeek-R1 生成的样本进行微调，展现出优秀的推理能力。在多个基准测试中表现不俗，其中在 MATH-500 上达到了 89.1% 的准确率，在 AIME 2024 上达到了 50.4% 的通过率，在 CodeForces 上获得了 1205 的评分，作为 8B 规模的模型展示了较强的数学和编程能力。",
        "displayName": "DeepSeek R1 Distill Llama 8B (Free)",
        "enabled": true,
        "type": "chat",
        "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力。",
        "displayName": "DeepSeek R1 Distill Qwen 7B (Free)",
        "enabled": true,
        "type": "chat",
        "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-R1-Distill-Qwen-1.5B 是基于 Qwen2.5-Math-1.5B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在多个基准测试中展现出不错的性能。作为一个轻量级模型，在 MATH-500 上达到了 83.9% 的准确率，在 AIME 2024 上达到了 28.9% 的通过率，在 CodeForces 上获得了 954 的评分，显示出超出其参数规模的推理能力。",
        "displayName": "DeepSeek-R1-Distill-Qwen-1.5B (Free)",
        "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "DeepSeek-V2.5 是 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的升级版本，集成了两个先前版本的通用和编码能力。该模型在多个方面进行了优化，包括写作和指令跟随能力，更好地与人类偏好保持一致。DeepSeek-V2.5 在各种评估基准上都取得了显著的提升，如 AlpacaEval 2.0、ArenaHard、AlignBench 和 MT-Bench 等",
        "displayName": "DeepSeek V2.5",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "deepseek-ai/DeepSeek-V2.5",
        "pricing": {
          "currency": "CNY",
          "input": 1.33,
          "output": 1.33
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "DeepSeek-VL2 是一个基于 DeepSeekMoE-27B 开发的混合专家（MoE）视觉语言模型，采用稀疏激活的 MoE 架构，在仅激活 4.5B 参数的情况下实现了卓越性能。该模型在视觉问答、光学字符识别、文档/表格/图表理解和视觉定位等多个任务中表现优异。",
        "displayName": "DeepSeek VL2",
        "id": "deepseek-ai/deepseek-vl2",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0.99,
          "output": 0.99
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "QVQ-72B-Preview 是由 Qwen 团队开发的专注于视觉推理能力的研究型模型，其在复杂场景理解和解决视觉相关的数学问题方面具有独特优势。",
        "displayName": "QVQ 72B Preview",
        "enabled": true,
        "type": "chat",
        "id": "Qwen/QVQ-72B-Preview",
        "pricing": {
          "currency": "CNY",
          "input": 9.9,
          "output": 9.9
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "QwQ-32B-Preview是Qwen 最新的实验性研究模型，专注于提升AI推理能力。通过探索语言混合、递归推理等复杂机制，主要优势包括强大的推理分析能力、数学和编程能力。与此同时，也存在语言切换问题、推理循环、安全性考虑、其他能力方面的差异。",
        "displayName": "QwQ 32B Preview",
        "enabled": true,
        "type": "chat",
        "id": "Qwen/QwQ-32B-Preview",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 7B Instruct (Free)",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 7B Instruct (LoRA)",
        "type": "chat",
        "id": "LoRA/Qwen/Qwen2.5-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.53,
          "output": 0.53
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 7B Instruct (Pro)",
        "type": "chat",
        "functionCall": true,
        "id": "Pro/Qwen/Qwen2.5-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.35,
          "output": 0.35
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 14B Instruct",
        "functionCall": true,
        "type": "chat",
        "id": "Qwen/Qwen2.5-14B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.7,
          "output": 0.7
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 32B Instruct",
        "functionCall": true,
        "type": "chat",
        "id": "Qwen/Qwen2.5-32B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 72B Instruct",
        "type": "chat",
        "functionCall": true,
        "id": "Qwen/Qwen2.5-72B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 72B Instruct (LoRA)",
        "id": "LoRA/Qwen/Qwen2.5-72B-Instruct",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 6.2,
          "output": 6.2
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 72B Instruct (Vendor-A)",
        "type": "chat",
        "functionCall": true,
        "id": "Vendor-A/Qwen/Qwen2.5-72B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 1
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的输入，可以生成超过 8K tokens 的长文本。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "displayName": "Qwen2.5 72B Instruct 128K",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "Qwen/Qwen2.5-72B-Instruct-128K",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
        "displayName": "Qwen2.5 Coder 7B Instruct (Free)",
        "id": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
        "displayName": "Qwen2.5 Coder 7B Instruct (Pro)",
        "id": "Pro/Qwen/Qwen2.5-Coder-7B-Instruct",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0.35,
          "output": 0.35
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2.5-Coder-32B-Instruct 是基于 Qwen2.5 开发的代码特定大语言模型。该模型通过 5.5 万亿 tokens 的训练，在代码生成、代码推理和代码修复方面都取得了显著提升。它是当前最先进的开源代码语言模型，编码能力可与 GPT-4 相媲美。模型不仅增强了编码能力，还保持了在数学和通用能力方面的优势，并支持长文本处理",
        "displayName": "Qwen2.5 Coder 32B Instruct",
        "type": "chat",
        "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
        "displayName": "Qwen2 1.5B Instruct (Free)",
        "id": "Qwen/Qwen2-1.5B-Instruct",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
        "displayName": "Qwen2 1.5B Instruct (Pro)",
        "type": "chat",
        "id": "Pro/Qwen/Qwen2-1.5B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.14,
          "output": 0.14
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
        "displayName": "Qwen2 7B Instruct (Free)",
        "type": "chat",
        "id": "Qwen/Qwen2-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
        "displayName": "Qwen2 7B Instruct (Pro)",
        "type": "chat",
        "id": "Pro/Qwen/Qwen2-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.35,
          "output": 0.35
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力",
        "displayName": "Qwen2 72B Instruct",
        "type": "chat",
        "id": "Qwen/Qwen2-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-VL-7B-Instruct 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够用于高质量的基于视频的问答、对话和内容创作，还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
        "displayName": "Qwen2 VL 7B Instruct (Pro)",
        "enabled": true,
        "type": "chat",
        "id": "Pro/Qwen/Qwen2-VL-7B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.35,
          "output": 0.35
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
        "displayName": "Qwen2 VL 72B Instruct",
        "enabled": true,
        "type": "chat",
        "id": "Qwen/Qwen2-VL-72B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域",
        "displayName": "InternLM2.5 7B Chat (Free)",
        "type": "chat",
        "functionCall": true,
        "id": "internlm/internlm25-7b-chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "InternLM2.5-20B-Chat 是一个开源的大规模对话模型，基于 InternLM2 架构开发。该模型拥有 200 亿参数，在数学推理方面表现出色，超越了同量级的 Llama3 和 Gemma2-27B 模型。InternLM2.5-20B-Chat 在工具调用能力方面有显著提升，支持从上百个网页收集信息进行分析推理，并具备更强的指令理解、工具选择和结果反思能力。它适用于构建复杂智能体，可进行多轮工具调用以完成复杂任务",
        "displayName": "InternLM2.5 20B Chat",
        "type": "chat",
        "functionCall": true,
        "id": "internlm/internlm25-20b-chat",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 1
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "InternVL2-8B 是 InternVL 2.0 系列多模态大语言模型中的一员。该模型由 InternViT-300M-448px 视觉模型、MLP 投影层和 internlm25-7b-chat 语言模型组成。它在各种视觉语言任务上展现出了卓越的性能，包括文档和图表理解、场景文本理解、OCR、科学和数学问题解决等。InternVL2-8B 使用 8K 上下文窗口训练，能够处理长文本、多图像和视频输入，显著提升了模型在这些任务上的处理能力",
        "displayName": "InternVL2 8B (Pro)",
        "type": "chat",
        "id": "Pro/OpenGVLab/InternVL2-8B",
        "pricing": {
          "currency": "CNY",
          "input": 0.35,
          "output": 0.35
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "InternVL2-26B 是 InternVL 2.0 系列多模态大语言模型中的一员。该模型由 InternViT-6B-448px-V1-5 视觉模型、MLP 投影层和 internlm2-chat-20b 语言模型组成。它在各种视觉语言任务上展现出了卓越的性能，包括文档和图表理解、场景文本理解、OCR、科学和数学问题解决等。InternVL2-26B 使用 8K 上下文窗口训练，能够处理长文本、多图像和视频输入，显著提升了模型在这些任务上的处理能力",
        "displayName": "InternVL2 26B",
        "type": "chat",
        "id": "OpenGVLab/InternVL2-26B",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 1
        },
        "vision": true
      },
      {
        "contextWindowTokens": 131072,
        "description": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
        "displayName": "GLM-4 9B Chat (Free)",
        "type": "chat",
        "functionCall": true,
        "id": "THUDM/glm-4-9b-chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
        "displayName": "GLM-4 9B Chat (Pro)",
        "functionCall": true,
        "type": "chat",
        "id": "Pro/THUDM/glm-4-9b-chat",
        "pricing": {
          "currency": "CNY",
          "input": 0.6,
          "output": 0.6
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用",
        "displayName": "ChatGLM3 6B (Free)",
        "type": "chat",
        "id": "THUDM/chatglm3-6b",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "Yi-1.5-6B-Chat 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型具有 4K、16K 和 32K 的上下文长度版本，预训练总量达到 3.6T 个 token",
        "displayName": "Yi-1.5 6B Chat (Free)",
        "type": "chat",
        "id": "01-ai/Yi-1.5-6B-Chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 16384,
        "description": "Yi-1.5-9B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在同等规模的开源模型中表现最佳",
        "displayName": "Yi-1.5 9B Chat 16K (Free)",
        "type": "chat",
        "id": "01-ai/Yi-1.5-9B-Chat-16K",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 16384,
        "description": "Yi-1.5-34B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在大多数基准测试中与更大的模型相当或表现更佳，具有 16K 的上下文长度",
        "displayName": "Yi-1.5 34B Chat 16K",
        "id": "01-ai/Yi-1.5-34B-Chat-16K",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "Gemma 是 Google 开发的轻量级、最先进的开放模型系列之一。它是一个仅解码器的大型语言模型，支持英语，提供开放权重、预训练变体和指令微调变体。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。该 9B 模型是通过 8 万亿个 tokens 训练而成。其相对较小的规模使其可以在资源有限的环境中部署，如笔记本电脑、台式机或您自己的云基础设施，从而使更多人能够访问最先进的 AI 模型并促进创新",
        "displayName": "Gemma 2 9B (Free)",
        "enabled": true,
        "type": "chat",
        "id": "google/gemma-2-9b-it",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "Gemma 是 Google 开发的轻量级、最先进的开放模型系列之一。它是一个仅解码器的大型语言模型，支持英语，提供开放权重、预训练变体和指令微调变体。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。该 9B 模型是通过 8 万亿个 tokens 训练而成。其相对较小的规模使其可以在资源有限的环境中部署，如笔记本电脑、台式机或您自己的云基础设施，从而使更多人能够访问最先进的 AI 模型并促进创新",
        "displayName": "Gemma 2 9B (Pro)",
        "id": "Pro/google/gemma-2-9b-it",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0.6,
          "output": 0.6
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "Gemma 是由 Google 开发的轻量级、最先进的开放模型系列，采用与 Gemini 模型相同的研究和技术构建。这些模型是仅解码器的大型语言模型，支持英语，提供预训练和指令微调两种变体的开放权重。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。其相对较小的规模使其能够部署在资源有限的环境中，如笔记本电脑、台式机或个人云基础设施，从而让所有人都能获得最先进的 AI 模型，促进创新",
        "displayName": "Gemma 2 27B",
        "enabled": true,
        "type": "chat",
        "id": "google/gemma-2-27b-it",
        "pricing": {
          "currency": "CNY",
          "input": 1.26,
          "output": 1.26
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.1 8B Instruct (Free)",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.1 8B Instruct (Pro)",
        "type": "chat",
        "id": "Pro/meta-llama/Meta-Llama-3.1-8B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.42,
          "output": 0.42
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 70B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.1 70B Instruct",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 405B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.1 405B Instruct",
        "type": "chat",
        "enabled": true,
        "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 21,
          "output": 21
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.3 70B Instruct",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "meta-llama/Llama-3.3-70B-Instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4.13,
          "output": 4.13
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "TeleChat2大模型是由中国电信从0到1自主研发的生成式语义大模型，支持百科问答、代码生成、长文生成等功能，为用户提供对话咨询服务，能够与用户进行对话互动，回答问题，协助创作，高效便捷地帮助用户获取信息、知识和灵感。模型在幻觉问题、长文生成、逻辑理解等方面均有较出色表现。",
        "displayName": "TeleChat2",
        "type": "chat",
        "id": "TeleAI/TeleChat2",
        "pricing": {
          "currency": "CNY",
          "input": 1.33,
          "output": 1.33
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "TeleMM多模态大模型是由中国电信自主研发的多模态理解大模型，能够处理文本、图像等多种模态输入，支持图像理解、图表分析等功能，为用户提供跨模态的理解服务。模型能够与用户进行多模态交互，准确理解输入内容，回答问题、协助创作，并高效提供多模态信息和灵感支持。在细粒度感知，逻辑推理等多模态任务上有出色表现",
        "displayName": "TeleMM",
        "type": "chat",
        "id": "TeleAI/TeleMM",
        "pricing": {
          "currency": "CNY",
          "input": 1.33,
          "output": 1.33
        },
        "vision": true
      }
    ]
  },
  {
    "provider": "Moonshot",
    "chatModels": [
      {
        "contextWindowTokens": 8192,
        "description": "Moonshot V1 8K 专为生成短文本任务设计，具有高效的处理性能，能够处理8,192个tokens，非常适合简短对话、速记和快速内容生成。",
        "displayName": "Moonshot V1 8K",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "moonshot-v1-8k"
      },
      {
        "contextWindowTokens": 32768,
        "description": "Moonshot V1 32K 提供中等长度的上下文处理能力，能够处理32,768个tokens，特别适合生成各种长文档和复杂对话，应用于内容创作、报告生成和对话系统等领域。",
        "displayName": "Moonshot V1 32K",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "moonshot-v1-32k"
      },
      {
        "contextWindowTokens": 128000,
        "description": "Moonshot V1 128K 是一款拥有超长上下文处理能力的模型，适用于生成超长文本，满足复杂的生成任务需求，能够处理多达128,000个tokens的内容，非常适合科研、学术和大型文档生成等应用场景。",
        "displayName": "Moonshot V1 128K",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "moonshot-v1-128k"
      }
    ]
  },
  {
    "provider": "GiteeAI",
    "chatModels": [
      {
        "contextWindowTokens": 16000,
        "description": "Qwen2.5-72B-Instruct  支持 16k 上下文, 生成长文本超过 8K 。支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。模型知识明显增加，并且大大提高了编码和数学能力, 多语言支持超过 29 种",
        "displayName": "Qwen2.5 72B Instruct",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "Qwen2.5-72B-Instruct"
      },
      {
        "contextWindowTokens": 32000,
        "description": "Qwen2.5-32B-Instruct 是一款 320 亿参数的大语言模型，性能表现均衡，优化中文和多语言场景，支持智能问答、内容生成等应用。",
        "displayName": "Qwen2.5 32B Instruct",
        "type": "chat",
        "enabled": true,
        "id": "Qwen2.5-32B-Instruct"
      },
      {
        "contextWindowTokens": 24000,
        "description": "Qwen2.5-14B-Instruct 是一款 140 亿参数的大语言模型，性能表现优秀，优化中文和多语言场景，支持智能问答、内容生成等应用。",
        "displayName": "Qwen2.5 14B Instruct",
        "type": "chat",
        "enabled": true,
        "id": "Qwen2.5-14B-Instruct"
      },
      {
        "contextWindowTokens": 32000,
        "description": "Qwen2.5-7B-Instruct 是一款 70 亿参数的大语言模型，支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。优化中文和多语言场景，支持智能问答、内容生成等应用。",
        "displayName": "Qwen2.5 7B Instruct",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "Qwen2.5-7B-Instruct"
      },
      {
        "contextWindowTokens": 32000,
        "description": "Qwen2 是 Qwen 模型的最新系列，对比当前最优的开源模型，Qwen2-72B 在自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的模型。",
        "displayName": "Qwen2 72B Instruct",
        "type": "chat",
        "id": "Qwen2-72B-Instruct"
      },
      {
        "contextWindowTokens": 24000,
        "description": "Qwen2 是 Qwen 模型的最新系列，能够超越同等规模的最优开源模型甚至更大规模的模型，Qwen2 7B 在多个评测上取得显著的优势，尤其是代码及中文理解上。",
        "displayName": "Qwen2 7B Instruct",
        "id": "Qwen2-7B-Instruct",
        "type": "chat"
      },
      {
        "contextWindowTokens": 32000,
        "description": "Qwen2.5-Coder-32B-Instruct 是一款专为代码生成、代码理解和高效开发场景设计的大型语言模型，采用了业界领先的32B参数规模，能够满足多样化的编程需求。",
        "displayName": "Qwen2.5 Coder 32B Instruct",
        "enabled": true,
        "type": "chat",
        "id": "Qwen2.5-Coder-32B-Instruct"
      },
      {
        "contextWindowTokens": 24000,
        "description": "Qwen2.5-Coder-14B-Instruct 是一款基于大规模预训练的编程指令模型，具备强大的代码理解和生成能力，能够高效地处理各种编程任务，特别适合智能代码编写、自动化脚本生成和编程问题解答。",
        "displayName": "Qwen2.5 Coder 14B Instruct",
        "enabled": true,
        "id": "Qwen2.5-Coder-14B-Instruct",
        "type": "chat"
      },
      {
        "contextWindowTokens": 32000,
        "description": "Qwen2-VL-72B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
        "displayName": "Qwen2 VL 72B",
        "enabled": true,
        "id": "Qwen2-VL-72B",
        "type": "chat",
        "vision": true
      },
      {
        "contextWindowTokens": 32000,
        "description": "InternVL2.5-26B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
        "displayName": "InternVL2.5 26B",
        "enabled": true,
        "id": "InternVL2.5-26B",
        "type": "chat",
        "vision": true
      },
      {
        "contextWindowTokens": 32000,
        "description": "InternVL2-8B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。",
        "displayName": "InternVL2 8B",
        "enabled": true,
        "id": "InternVL2-8B",
        "type": "chat",
        "vision": true
      },
      {
        "contextWindowTokens": 32000,
        "description": "GLM-4-9B-Chat 在语义、数学、推理、代码和知识等多方面均表现出较高性能。还具备网页浏览、代码执行、自定义工具调用和长文本推理。 支持包括日语，韩语，德语在内的 26 种语言。",
        "displayName": "GLM4 9B Chat",
        "enabled": true,
        "type": "chat",
        "id": "glm-4-9b-chat"
      },
      {
        "contextWindowTokens": 4000,
        "description": "Yi-1.5-34B-Chat 在保持原系列模型优秀的通用语言能力的前提下，通过增量训练 5 千亿高质量 token，大幅提高了数学逻辑、代码能力。",
        "displayName": "Yi 34B Chat",
        "type": "chat",
        "enabled": true,
        "id": "Yi-34B-Chat"
      },
      {
        "contextWindowTokens": 8000,
        "description": "DeepSeek Coder 33B 是一个代码语言模型， 基于 2 万亿数据训练而成，其中 87% 为代码， 13% 为中英文语言。模型引入 16K 窗口大小和填空任务，提供项目级别的代码补全和片段填充功能。",
        "displayName": "DeepSeek Coder 33B Instruct",
        "type": "chat",
        "enabled": true,
        "id": "deepseek-coder-33B-instruct"
      },
      {
        "contextWindowTokens": 32000,
        "description": "CodeGeeX4-ALL-9B 是一个多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。",
        "displayName": "CodeGeeX4 All 9B",
        "type": "chat",
        "enabled": true,
        "id": "codegeex4-all-9b"
      }
    ]
  },
  {
    "provider": "Github",
    "chatModels": [
      {
        "contextWindowTokens": 200000,
        "description": "专注于高级推理和解决复杂问题，包括数学和科学任务。非常适合需要深入上下文理解和代理工作流程的应用程序。",
        "displayName": "OpenAI o1",
        "enabled": true,
        "functionCall": false,
        "type": "chat",
        "id": "o1",
        "maxOutput": 100000,
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "比 o1-preview 更小、更快，成本低80%，在代码生成和小上下文操作方面表现良好。",
        "displayName": "OpenAI o1-mini",
        "enabled": true,
        "functionCall": false,
        "id": "o1-mini",
        "type": "chat",
        "maxOutput": 65536,
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "专注于高级推理和解决复杂问题，包括数学和科学任务。非常适合需要深度上下文理解和自主工作流程的应用。",
        "displayName": "OpenAI o1-preview",
        "enabled": true,
        "functionCall": false,
        "id": "o1-preview",
        "type": "chat",
        "maxOutput": 32768,
        "vision": true
      },
      {
        "contextWindowTokens": 134144,
        "description": "一种经济高效的AI解决方案，适用于多种文本和图像任务。",
        "displayName": "OpenAI GPT-4o mini",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o-mini",
        "maxOutput": 4096,
        "vision": true
      },
      {
        "contextWindowTokens": 134144,
        "description": "OpenAI GPT-4系列中最先进的多模态模型，可以处理文本和图像输入。",
        "displayName": "OpenAI GPT-4o",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "gpt-4o",
        "maxOutput": 16384,
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "displayName": "DeepSeek R1",
        "type": "chat",
        "id": "DeepSeek-R1",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 262144,
        "description": "一个52B参数（12B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。",
        "displayName": "AI21 Jamba 1.5 Mini",
        "functionCall": true,
        "type": "chat",
        "id": "ai21-jamba-1.5-mini",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 262144,
        "description": "一个398B参数（94B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。",
        "displayName": "AI21 Jamba 1.5 Large",
        "functionCall": true,
        "type": "chat",
        "id": "ai21-jamba-1.5-large",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Command R是一个可扩展的生成模型，旨在针对RAG和工具使用，使企业能够实现生产级AI。",
        "displayName": "Cohere Command R",
        "id": "cohere-command-r",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Command R+是一个最先进的RAG优化模型，旨在应对企业级工作负载。",
        "displayName": "Cohere Command R+",
        "type": "chat",
        "id": "cohere-command-r-plus",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Mistral Nemo是一种尖端的语言模型（LLM），在其尺寸类别中拥有最先进的推理、世界知识和编码能力。",
        "displayName": "Mistral Nemo",
        "type": "chat",
        "id": "mistral-nemo",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Mistral Small可用于任何需要高效率和低延迟的基于语言的任务。",
        "displayName": "Mistral Small",
        "type": "chat",
        "id": "mistral-small",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Mistral的旗舰模型，适合需要大规模推理能力或高度专业化的复杂任务（合成文本生成、代码生成、RAG或代理）。",
        "displayName": "Mistral Large",
        "type": "chat",
        "id": "mistral-large",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 262144,
        "displayName": "Codestral",
        "id": "Codestral-2501",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "在高分辨率图像上表现出色的图像推理能力，适用于视觉理解应用。",
        "displayName": "Llama 3.2 11B Vision",
        "id": "llama-3.2-11b-vision-instruct",
        "type": "chat",
        "maxOutput": 4096,
        "vision": true
      },
      {
        "contextWindowTokens": 131072,
        "description": "适用于视觉理解代理应用的高级图像推理能力。",
        "displayName": "Llama 3.2 90B Vision",
        "id": "llama-3.2-90b-vision-instruct",
        "type": "chat",
        "maxOutput": 4096,
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月",
        "displayName": "Llama 3.3 70B Instruct",
        "type": "chat",
        "enabled": true,
        "functionCall": true,
        "id": "llama-3.3-70b-instruct"
      },
      {
        "contextWindowTokens": 131072,
        "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
        "displayName": "Meta Llama 3.1 8B",
        "type": "chat",
        "id": "meta-llama-3.1-8b-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
        "displayName": "Meta Llama 3.1 70B",
        "id": "meta-llama-3.1-70b-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。",
        "displayName": "Meta Llama 3.1 405B",
        "type": "chat",
        "id": "meta-llama-3.1-405b-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 8192,
        "description": "一个多功能的80亿参数模型，针对对话和文本生成任务进行了优化。",
        "displayName": "Meta Llama 3 8B",
        "id": "meta-llama-3-8b-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 8192,
        "description": "一个强大的700亿参数模型，在推理、编码和广泛的语言应用方面表现出色。",
        "displayName": "Meta Llama 3 70B",
        "id": "meta-llama-3-70b-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 16384,
        "displayName": "Phi 4",
        "type": "chat",
        "id": "Phi-4",
        "maxOutput": 16384
      },
      {
        "contextWindowTokens": 131072,
        "displayName": "Phi 3.5 MoE",
        "id": "Phi-3.5-MoE-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Phi-3-mini模型的更新版。",
        "displayName": "Phi-3.5-mini 128K",
        "type": "chat",
        "id": "Phi-3.5-mini-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "Phi-3-vision模型的更新版。",
        "displayName": "Phi-3.5-vision 128K",
        "type": "chat",
        "id": "Phi-3.5-vision-instrust",
        "maxOutput": 4096,
        "vision": true
      },
      {
        "contextWindowTokens": 4096,
        "description": "Phi-3家族中最小的成员，针对质量和低延迟进行了优化。",
        "displayName": "Phi-3-mini 4K",
        "id": "Phi-3-mini-4k-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "相同的Phi-3-mini模型，但具有更大的上下文大小，适用于RAG或少量提示。",
        "displayName": "Phi-3-mini 128K",
        "type": "chat",
        "id": "Phi-3-mini-128k-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 8192,
        "description": "一个70亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。",
        "displayName": "Phi-3-small 8K",
        "id": "Phi-3-small-8k-instruct",
        "type": "chat",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "相同的Phi-3-small模型，但具有更大的上下文大小，适用于RAG或少量提示。",
        "displayName": "Phi-3-small 128K",
        "type": "chat",
        "id": "Phi-3-small-128k-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 4096,
        "description": "一个140亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。",
        "displayName": "Phi-3-medium 4K",
        "type": "chat",
        "id": "Phi-3-medium-4k-instruct",
        "maxOutput": 4096
      },
      {
        "contextWindowTokens": 131072,
        "description": "相同的Phi-3-medium模型，但具有更大的上下文大小，适用于RAG或少量提示。",
        "displayName": "Phi-3-medium 128K",
        "type": "chat",
        "id": "Phi-3-medium-128k-instruct",
        "maxOutput": 4096
      }
    ]
  },
  {
    "provider": "Qwen",
    "chatModels": [
      {
        "contextWindowTokens": 1000000,
        "description": "通义千问超大规模语言模型，支持中文、英文等不同语言输入。",
        "displayName": "Qwen Turbo",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "qwen-turbo-latest",
        "pricing": {
          "currency": "CNY",
          "input": 0.3,
          "output": 0.6
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问超大规模语言模型增强版，支持中文、英文等不同语言输入。",
        "displayName": "Qwen Plus",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "qwen-plus-latest",
        "pricing": {
          "currency": "CNY",
          "input": 0.8,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "通义千问千亿级别超大规模语言模型，支持中文、英文等不同语言输入，当前通义千问2.5产品版本背后的API模型。",
        "displayName": "Qwen Max",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "qwen-max-latest",
        "pricing": {
          "currency": "CNY",
          "input": 20,
          "output": 60
        }
      },
      {
        "contextWindowTokens": 1000000,
        "description": "通义千问超大规模语言模型，支持长文本上下文，以及基于长文档、多文档等多个场景的对话功能。",
        "displayName": "Qwen Long",
        "id": "qwen-long",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0.5,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 32000,
        "description": "通义千问大规模视觉语言模型增强版。大幅提升细节识别能力和文字识别能力，支持超百万像素分辨率和任意长宽比规格的图像。",
        "displayName": "Qwen VL Plus",
        "type": "chat",
        "enabled": true,
        "id": "qwen-vl-plus-latest",
        "pricing": {
          "currency": "CNY",
          "input": 1.5,
          "output": 4.5
        },
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "通义千问超大规模视觉语言模型。相比增强版，再次提升视觉推理能力和指令遵循能力，提供更高的视觉感知和认知水平。",
        "displayName": "Qwen VL Max",
        "type": "chat",
        "enabled": true,
        "id": "qwen-vl-max-latest",
        "pricing": {
          "currency": "CNY",
          "input": 3,
          "output": 9
        },
        "vision": true
      },
      {
        "contextWindowTokens": 34096,
        "description": "通义千问OCR是文字提取专有模型，专注于文档、表格、试题、手写体文字等类型图像的文字提取能力。它能够识别多种文字，目前支持的语言有：汉语、英语、法语、日语、韩语、德语、俄语、意大利语、越南语、阿拉伯语。",
        "displayName": "Qwen VL OCR",
        "type": "chat",
        "id": "qwen-vl-ocr-latest",
        "pricing": {
          "currency": "CNY",
          "input": 5,
          "output": 5
        },
        "vision": true
      },
      {
        "contextWindowTokens": 4096,
        "description": "通义千问数学模型是专门用于数学解题的语言模型。",
        "displayName": "Qwen Math Turbo",
        "id": "qwen-math-turbo-latest",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 2,
          "output": 6
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "通义千问数学模型是专门用于数学解题的语言模型。",
        "displayName": "Qwen Math Plus",
        "type": "chat",
        "id": "qwen-math-plus-latest",
        "pricing": {
          "currency": "CNY",
          "input": 4,
          "output": 12
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问代码模型。",
        "type": "chat",
        "displayName": "Qwen Coder Turbo",
        "id": "qwen-coder-turbo-latest",
        "pricing": {
          "currency": "CNY",
          "input": 2,
          "output": 6
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问代码模型。",
        "displayName": "Qwen Coder Plus",
        "type": "chat",
        "id": "qwen-coder-plus-latest",
        "pricing": {
          "currency": "CNY",
          "input": 3.5,
          "output": 7
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "QwQ模型是由 Qwen 团队开发的实验性研究模型，专注于增强 AI 推理能力。",
        "displayName": "QwQ 32B Preview",
        "type": "chat",
        "id": "qwq-32b-preview",
        "pricing": {
          "currency": "CNY",
          "input": 3.5,
          "output": 7
        }
      },
      {
        "contextWindowTokens": 32768,
        "description": "QVQ模型是由 Qwen 团队开发的实验性研究模型，专注于提升视觉推理能力，尤其在数学推理领域。",
        "displayName": "QVQ 72B Preview",
        "id": "qvq-72b-preview",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 12,
          "output": 36
        },
        "releasedAt": "2024-12-25",
        "vision": true
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问2.5对外开源的7B规模的模型。",
        "displayName": "Qwen2.5 7B",
        "type": "chat",
        "functionCall": true,
        "id": "qwen2.5-7b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 0.5,
          "output": 1
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问2.5对外开源的14B规模的模型。",
        "displayName": "Qwen2.5 14B",
        "type": "chat",
        "functionCall": true,
        "id": "qwen2.5-14b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 3
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问2.5对外开源的32B规模的模型。",
        "displayName": "Qwen2.5 32B",
        "functionCall": true,
        "id": "qwen2.5-32b-instruct",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 3.5,
          "output": 7
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问2.5对外开源的72B规模的模型。",
        "displayName": "Qwen2.5 72B",
        "type": "chat",
        "functionCall": true,
        "id": "qwen2.5-72b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4,
          "output": 12
        }
      },
      {
        "contextWindowTokens": 1000000,
        "description": "通义千问2.5对外开源的72B规模的模型。",
        "displayName": "Qwen2.5 14B 1M",
        "functionCall": true,
        "type": "chat",
        "id": "qwen2.5-14b-instruct-1m",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 3
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "Qwen-Math 模型具有强大的数学解题能力。",
        "displayName": "Qwen2.5 Math 7B",
        "type": "chat",
        "id": "qwen2.5-math-7b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 4096,
        "description": "Qwen-Math 模型具有强大的数学解题能力。",
        "displayName": "Qwen2.5 Math 72B",
        "type": "chat",
        "id": "qwen2.5-math-72b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 4,
          "output": 12
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问代码模型开源版。",
        "displayName": "Qwen2.5 Coder 7B",
        "type": "chat",
        "id": "qwen2.5-coder-7b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 1,
          "output": 2
        }
      },
      {
        "contextWindowTokens": 131072,
        "description": "通义千问代码模型开源版。",
        "displayName": "Qwen2.5 Coder 32B",
        "type": "chat",
        "id": "qwen2.5-coder-32b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 3.5,
          "output": 7
        }
      },
      {
        "contextWindowTokens": 8000,
        "description": "以 Qwen-7B 语言模型初始化，添加图像模型，图像输入分辨率为448的预训练模型。",
        "displayName": "Qwen VL",
        "id": "qwen-vl-v1",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "vision": true
      },
      {
        "contextWindowTokens": 8000,
        "description": "通义千问VL支持灵活的交互方式，包括多图、多轮问答、创作等能力的模型。",
        "displayName": "Qwen VL Chat",
        "type": "chat",
        "id": "qwen-vl-chat-v1",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "vision": true
      },
      {
        "contextWindowTokens": 128000,
        "description": "指令跟随、数学、解题、代码整体提升，万物识别能力提升，支持多样格式直接精准定位视觉元素，支持对长视频文件（最长10分钟）进行理解和秒级别的事件时刻定位，能理解时间先后和快慢，基于解析和定位能力支持操控OS或Mobile的Agent，关键信息抽取能力和Json格式输出能力强，此版本为72B版本，本系列能力最强的版本。",
        "displayName": "Qwen2.5 VL 72B",
        "type": "chat",
        "id": "qwen2.5-vl-72b-instruct",
        "pricing": {
          "currency": "CNY",
          "input": 16,
          "output": 48
        },
        "releasedAt": "2025-01-26",
        "vision": true
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能较高，能力较强。",
        "displayName": "DeepSeek R1",
        "id": "deepseek-r1",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-01-27"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-V3 为自研 MoE 模型，671B 参数，激活 37B，在 14.8T token 上进行了预训练，在长文本、代码、数学、百科、中文能力上表现优秀。",
        "displayName": "DeepSeek V3",
        "type": "chat",
        "id": "deepseek-v3",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-01-27"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Qwen-1.5B 是一个基于 Qwen2.5-Math-1.5B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Qwen 1.5B",
        "id": "deepseek-r1-distill-qwen-1.5b",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Qwen-7B 是一个基于 Qwen2.5-Math-7B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Qwen 7B",
        "type": "chat",
        "id": "deepseek-r1-distill-qwen-7b",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Qwen-14B 是一个基于 Qwen2.5-14B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Qwen 14B",
        "id": "deepseek-r1-distill-qwen-14b",
        "type": "chat",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Qwen-32B 是一个基于 Qwen2.5-32B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Qwen 32B",
        "type": "chat",
        "id": "deepseek-r1-distill-qwen-32b",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Llama-8B 是一个基于 Llama-3.1-8B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Llama 8B",
        "type": "chat",
        "id": "deepseek-r1-distill-llama-8b",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      },
      {
        "contextWindowTokens": 131072,
        "description": "DeepSeek-R1-Distill-Llama-70B 是一个基于 Llama-3.3-70B-Instruct 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。",
        "displayName": "DeepSeek R1 Distill Llama 70B",
        "type": "chat",
        "id": "deepseek-r1-distill-llama-70b",
        "pricing": {
          "currency": "CNY",
          "input": 0,
          "output": 0
        },
        "releasedAt": "2025-02-05"
      }
    ]
  },
  {
    "provider": "Grok",
    "chatModels": [
      {
        "contextWindowTokens": 131072,
        "description": "拥有与 Grok 2 相当的性能，但具有更高的效率、速度和功能。",
        "displayName": "Grok Beta",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "grok-beta",
        "pricing": {
          "input": 5,
          "output": 15
        }
      },
      {
        "contextWindowTokens": 8192,
        "description": "最新的图像理解模型，可以处理各种各样的视觉信息，包括文档、图表、截图和照片等。",
        "displayName": "Grok Vision Beta",
        "enabled": true,
        "functionCall": true,
        "id": "grok-vision-beta",
        "type": "chat",
        "pricing": {
          "input": 5,
          "output": 15
        },
        "vision": true
      },
      {
        "contextWindowTokens": 131072,
        "description": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
        "displayName": "Grok 2 1212",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "grok-2-1212",
        "pricing": {
          "input": 2,
          "output": 10
        },
        "releasedAt": "2024-12-12"
      },
      {
        "contextWindowTokens": 32768,
        "description": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
        "displayName": "Grok 2 Vision 1212",
        "enabled": true,
        "type": "chat",
        "functionCall": true,
        "id": "grok-2-vision-1212",
        "pricing": {
          "input": 2,
          "output": 10
        },
        "releasedAt": "2024-12-12",
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
        "displayName": "Grok 3",
        "enabled": true,
        "functionCall": true,
        "id": "grok-3",
        "type": "chat",
        "pricing": {
          "input": 2,
          "output": 10
        },
        "releasedAt": "2024-12-12",
        "vision": true
      },
      {
        "contextWindowTokens": 32768,
        "description": "该模型在准确性、指令遵循和多语言能力方面有所改进。",
        "displayName": "Grok 3 reasoner",
        "enabled": true,
        "functionCall": true,
        "type": "chat",
        "id": "grok-3-reasoner",
        "pricing": {
          "input": 2,
          "output": 10
        },
        "releasedAt": "2025-02-28",
        "vision": true
      }
    ]
  }
]